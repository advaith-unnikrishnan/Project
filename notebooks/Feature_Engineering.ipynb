{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzCQ2toaKa32"
      },
      "source": [
        "# Feature Engineering for Malawi Flood Prediction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# % pip install pyshp\n",
        "# % pip install geopandas"
      ],
      "metadata": {
        "id": "i8I8h5KpUwek"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "5sdNqKSZKa36"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "from tqdm import tqdm\n",
        "from shapely.geometry import Point\n",
        "from shapely.geometry.polygon import Polygon"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AssvSiH_U5am",
        "outputId": "7b2a04ad-ade6-40ea-ede9-9002db0cf4ef"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXNSNm5CKa4A"
      },
      "source": [
        "## Reading the data\n",
        "*shapes* is a open-source dataset containing polygons of administrative regions in Malawi\n",
        "\n",
        "*water* is a open-source dataset containing polygons of water bodies in the Africa continent\n",
        "\n",
        "In this way, we can categorise the features we generate into 2 types: Square features and Region features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "y78eA-uQKa4C"
      },
      "outputs": [],
      "source": [
        "# read in data files\n",
        "train = pd.read_csv(\"/content/drive/MyDrive/Final Project/Train.csv\")\n",
        "shapes = gpd.read_file(\"/content/drive/MyDrive/Final Project/mwi_adm_nso_20181016_shp/mwi_admbnda_adm3_nso_20181016.shp\")\n",
        "water = gpd.read_file('/content/drive/MyDrive/Final Project/africawaterbody/Africa_waterbody.shp')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzYOxk_yKa4G"
      },
      "source": [
        "## Helper functions\n",
        "\n",
        "We define a *haversine* function to calculate the angular distance between two sets of coordinates. \n",
        "\n",
        "The *encodePolygon* function is to match each Square to an administrative region provided in *shapes*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "x1srZAs6Ka4H"
      },
      "outputs": [],
      "source": [
        "from math import radians, cos, sin, asin, sqrt\n",
        "\n",
        "def haversine(lon1, lat1, lon2, lat2):\n",
        "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
        "    dlon = lon2 - lon1 \n",
        "    dlat = lat2 - lat1 \n",
        "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
        "    c = 2 * asin(sqrt(a)) \n",
        "    r = 6371\n",
        "    return c * r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "lC7ImOeiKa4K"
      },
      "outputs": [],
      "source": [
        "# function to match Square_ID to administrative region provided in shape file \n",
        "def encodePolygon(points, polygons):\n",
        "    numPoints = len(points)\n",
        "    numPolygons = len(polygons)\n",
        "    for idx, point in tqdm(enumerate(points)):\n",
        "        row = np.zeros(numPolygons)\n",
        "        for idx2, polygon in enumerate(polygons):\n",
        "            if polygon.contains(point):\n",
        "                row[idx2] = 1\n",
        "                break\n",
        "        if idx == 0:\n",
        "            matrix = row\n",
        "        else:\n",
        "            matrix = np.vstack((matrix,row))\n",
        "    return matrix.transpose()    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgXkhbvVKa4M"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "CggG0n6IKa4N"
      },
      "outputs": [],
      "source": [
        "train2015 = train.drop([col for col in train.columns if '2019' in col],axis=1)\n",
        "precip = [i for i in range(1,18)]\n",
        "train2015.columns = ['X','Y','target','elevation']+precip+['LC_Type1_mode','id']\n",
        "train2015['sum'] = train2015[precip].apply(lambda x: x.sum(),axis=1)\n",
        "train2015['mean'] = train2015[precip].apply(lambda x: x.mean(),axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQMdaKc_Ka4P"
      },
      "source": [
        "## Obtaining region features\n",
        "\n",
        "Region features refer to features related to each administrative region, for instance, average rainfall in the region and average elevation in the region"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "collapsed": true,
        "id": "Kfby7_-4Ka4Q",
        "outputId": "19e6f4e5-5bd2-4ab3-d340-f6dd9850fca5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "16466it [02:26, 112.18it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in true_divide\n"
          ]
        }
      ],
      "source": [
        "# match Square_ID to administrative region and calculate flooding extent, total rainfall and elevation for each region\n",
        "points = []\n",
        "for point in zip(train2015.X.values,train2015.Y.values):\n",
        "    points.append(Point(point[0],point[1]))\n",
        "polygons = shapes.geometry.values\n",
        "    \n",
        "point_polygon_matrix = encodePolygon(points,polygons)\n",
        "numPoints = point_polygon_matrix.sum(axis=1).transpose()\n",
        "shapes = shapes.assign(num_points = numPoints)\n",
        "\n",
        "# rainfall\n",
        "rainfall = train2015['sum'].values\n",
        "rainfall_polygons = point_polygon_matrix.dot(rainfall.transpose())\n",
        "rainfall_polygons = rainfall_polygons / numPoints\n",
        "# elevation\n",
        "elevation = train2015.elevation.values\n",
        "elevation_polygons = point_polygon_matrix.dot(elevation.transpose())\n",
        "elevation_polygons = elevation_polygons / numPoints\n",
        "\n",
        "shapes = shapes.assign(rainfall=rainfall_polygons)\n",
        "shapes = shapes.assign(elevation=elevation_polygons)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "point_polygon_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wp4J-duQXhTp",
        "outputId": "54cda713-adc5-4c96-cf14-09844ec34cbb"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(368, 16466)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shapes = shapes[shapes.num_points!=0]\n",
        "shapes = shapes.reset_index()\n",
        "shapes.columns = ['poly_idx' if x=='index' else x for x in shapes.columns]"
      ],
      "metadata": {
        "id": "fg3aDfjKXfEh"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "bdsQ6QuHKa4U"
      },
      "outputs": [],
      "source": [
        "shapes.columns = ['poly_rainfall' if x=='rainfall' else x for x in shapes.columns]\n",
        "shapes.columns = ['poly_elevation' if x=='elevation' else x for x in shapes.columns]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "WYjiD2kyKa4X"
      },
      "outputs": [],
      "source": [
        "# join with shapes -- get polygon features\n",
        "a,b = np.where(point_polygon_matrix==1) #coordinates of matrix\n",
        "polygon_map = pd.DataFrame({'poly_idx':a,'square_idx':b})\n",
        "features = train2015.reset_index()\n",
        "\n",
        "#square_idx for mapping polygon_map and features\n",
        "features.columns = ['square_idx' if x=='index' else x for x in features.columns]\n",
        "features = features.merge(polygon_map,on='square_idx',how='outer')\n",
        "features.poly_idx = features.poly_idx.fillna(-1)\n",
        "\n",
        "#poly_idx for mapping features with shapes\n",
        "features = features.merge(shapes[['poly_idx','poly_rainfall','poly_elevation']],on='poly_idx',how='left')\n",
        "features.loc[features.poly_rainfall.isna(),'poly_rainfall'] = features['sum']\n",
        "features.loc[features.poly_elevation.isna(),'poly_elevation'] = features['elevation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "rKacaEQ_Ka4Y"
      },
      "outputs": [],
      "source": [
        "# get diff between shape and polygon\n",
        "features['elev_diff'] = features['elevation'] - features['poly_elevation']\n",
        "features['rainfall_diff'] = features['sum'] - features['poly_rainfall']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ctu8kFfNKa4Z"
      },
      "source": [
        "## Generate features from water body dataset\n",
        "\n",
        "Using the water body dataset, we can generate an additional Region feature -- number of water bodies in each Region. We can also generate an additional Square feature -- closest water body to each Square. This is useful because from the EDA we see that Squares close to water bodies are most affected by the floods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "NnUpqlb_Ka4a",
        "outputId": "b40df1e7-636c-499c-b85c-5dd3bdbfae94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "  \"\"\"\n",
            "833it [00:02, 385.30it/s]\n"
          ]
        }
      ],
      "source": [
        "# get water features (number of water bodies in each region, distance to closest water body)\n",
        "water = water.reset_index()\n",
        "water.columns = ['water_idx' if x=='index' else x for x in water.columns]\n",
        "water['centroid_lng'] = water.geometry.centroid.x\n",
        "water['centroid_lat'] = water.geometry.centroid.y\n",
        "water_centroids = []\n",
        "for poly in water.geometry.values:\n",
        "    water_centroids.append(poly.centroid)\n",
        "\n",
        "water_point_polygon_matrix = encodePolygon(water_centroids,polygons)\n",
        "\n",
        "a,b = np.where(water_point_polygon_matrix==1)\n",
        "water_polygon_map = pd.DataFrame({'poly_idx':a,'water_idx':b})\n",
        "# get number of water bodies in each polygon\n",
        "water_polygon_count = water_polygon_map.groupby('poly_idx').count().reset_index()\n",
        "water_polygon_count.columns = ['poly_idx','water_count']\n",
        "features = features.merge(water_polygon_count,on='poly_idx',how='left')\n",
        "features.water_count = features.water_count.fillna(0)\n",
        "# get distance to closest water body\n",
        "water_polygon_map = water_polygon_map.merge(water[['water_idx','centroid_lng','centroid_lat']],on='water_idx')\n",
        "closest_water= features.merge(water_polygon_map,on='poly_idx',how='left')\n",
        "closest_water= closest_water.dropna()\n",
        "closest_water= closest_water[['square_idx','X','Y','centroid_lng','centroid_lat']]\n",
        "closest_water['water_dist'] = closest_water[['X','Y','centroid_lng','centroid_lat']].apply(lambda x: haversine(x.X,x.Y,x.centroid_lng,x.centroid_lat),axis=1)\n",
        "closest_water = closest_water.groupby('square_idx')['water_dist'].min().to_frame().reset_index()\n",
        "features = features.merge(closest_water,on='square_idx',how='left')\n",
        "features.water_dist = features.water_dist.fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "vREUaYGlKa4c"
      },
      "outputs": [],
      "source": [
        "feature_cols = ['sum','mean','elevation','poly_rainfall','poly_elevation',\n",
        "                'elev_diff','rainfall_diff','water_count','water_dist']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4NSzHPbKa4e"
      },
      "source": [
        "## Save feature file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "tN7WsCcnKa4f"
      },
      "outputs": [],
      "source": [
        "features.to_pickle('features.pkl')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Feature Engineering.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}